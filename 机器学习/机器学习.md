<!--
 * @Description: 
 * @version: 1.0
 * @Author: xuxiaming
 * @Date: 2023-03-04 21:04:43
 * @LastEditors: xuxiaming
 * @LastEditTime: 2023-03-05 22:27:58
-->
概念介绍：
人工智能 > 机器学习  > 深度学习

分类：
监督学习：
  回归
  分类（判别模型，生成模型）
典型的生成模型：
  贝叶斯分类器
  高斯混合模型
  贝叶斯网络
  隐马尔可夫模型
  受限玻尔兹曼机
  生成对抗网络
  变分自动编码器
典型的判别模型：
  决策树
  kNN算法
  人工神经网络
  支持向量机
  logistic回归
  softmax回归
  随机森林
  boosting算法
  条件随机场


无监督学习：
  聚类
  降维
半监督学习
强化学习：立即做出反馈(机器人/自动驾驶)

决策树：
  贷款（年收入大于x,有房产）
  瓜的分类(色泽/敲声/纹理/根蒂/触感 分类->好瓜坏瓜)  && 信息增益

聚类：
  K-means ：
  原则：簇内距离小，簇间距离大
  初始化K个聚类中心->为每个个体分配聚类中心->移动聚类中心->重复迭代, 直到聚类中心不变或者变化很小

直观感受：通过变量去拟合/分类

模型评价：
  训练集/验证集/测试集= 7:1:2
  精度/召回率/准确率...
  过拟合/欠拟合

2大问题：回归和分类

视觉方面
语音方面
自然语言处理
....

人工神经网络的基础概念
  受人工神经网络启发的一种仿生的方法。

基本单位:神经元，输入数据-->计算(加权求和 + 偏执项 -> 激活函数 f(ax + b) )-->输出
  [激活函数](https://baike.baidu.com/item/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/2520792?fr=aladdin)：将映射转化为非线性的
  [损失函数](https://baike.baidu.com/item/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/1783236?fr=aladdin)：衡量模型预测结果与实际结果差距，优化模型。

  [全连接层](https://image.baidu.com/search/detail?ct=503316480&z=0&ipn=d&word=%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82&step_word=&hs=0&pn=0&spn=0&di=7189064908862914561&pi=0&rn=1&tn=baiduimagedetail&is=0%2C0&istype=0&ie=utf-8&oe=utf-8&in=&cl=2&lm=-1&st=undefined&cs=4027405161%2C484407927&os=478452879%2C823509600&simid=4027405161%2C484407927&adpicid=0&lpn=0&ln=1692&fr=&fmq=1678011761078_R&fm=&ic=undefined&s=undefined&hd=undefined&latest=undefined&copyright=undefined&se=&sme=&tab=0&width=undefined&height=undefined&face=undefined&ist=&jit=&cg=&bdtype=0&oriquery=&objurl=https%3A%2F%2Fimg-blog.csdnimg.cn%2Fimg_convert%2Fad626287f2b369ebf70e8bf707241aee.png&fromurl=ippr_z2C%24qAzdH3FAzdH3Fks52_z%26e3Bvf1g_z%26e3BgjpAzdH3Fojtxtg_nlcm89n8AzdH3Fw6ptvsjAzdH3F1jpwtsfAzdH3F888n0cbdd&gsm=1e&rpstart=0&rpnum=0&islist=&querylist=&nojc=undefined&dyTabStr=MCwzLDIsMSw2LDQsNSw4LDcsOQ%3D%3D)



mnist-实现
```python
import tensorflow as tf
 
mnist = tf.keras.datasets.mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0
 
model = tf.keras.models.Sequential([
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])
 
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
              metrics=['sparse_categorical_accuracy'])
 
model.fit(x_train, y_train, batch_size=32, epochs=5, validation_data=(x_test, y_test), validation_freq=1)
model.summary()
```

鸢尾花-实现
```python
# -*- coding: UTF-8 -*-
# 利用鸢尾花数据集，实现前向传播、反向传播，可视化loss曲线
 
# 导入所需模块
import tensorflow as tf
from sklearn import datasets
from matplotlib import pyplot as plt
import numpy as np
 
# 导入数据，分别为输入特征和标签
x_data = datasets.load_iris().data
y_data = datasets.load_iris().target
 
# 随机打乱数据（因为原始数据是顺序的，顺序不打乱会影响准确率）
# seed: 随机数种子，是一个整数，当设置之后，每次生成的随机数都一样（为方便教学，以保每位同学结果一致）
np.random.seed(116)  # 使用相同的seed，保证输入特征和标签一一对应
np.random.shuffle(x_data)
np.random.seed(116)
np.random.shuffle(y_data)
tf.random.set_seed(116)
 
# 将打乱后的数据集分割为训练集和测试集，训练集为前120行，测试集为后30行
x_train = x_data[:-30]
y_train = y_data[:-30]
x_test = x_data[-30:]
y_test = y_data[-30:]
 
# 转换x的数据类型，否则后面矩阵相乘时会因数据类型不一致报错
x_train = tf.cast(x_train, tf.float32)
x_test = tf.cast(x_test, tf.float32)
 
# from_tensor_slices函数使输入特征和标签值一一对应。（把数据集分批次，每个批次batch组数据）
train_db = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)
test_db = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)
 
# 生成神经网络的参数，4个输入特征故，输入层为4个输入节点；因为3分类，故输出层为3个神经元
# 用tf.Variable()标记参数可训练
# 使用seed使每次生成的随机数相同（方便教学，使大家结果都一致，在现实使用时不写seed）
w1 = tf.Variable(tf.random.truncated_normal([4, 3], stddev=0.1, seed=1))
b1 = tf.Variable(tf.random.truncated_normal([3], stddev=0.1, seed=1))
 
lr = 0.1  # 学习率为0.1
train_loss_results = []  # 将每轮的loss记录在此列表中，为后续画loss曲线提供数据
test_acc = []  # 将每轮的acc记录在此列表中，为后续画acc曲线提供数据
epoch = 500  # 循环500轮
loss_all = 0  # 每轮分4个step，loss_all记录四个step生成的4个loss的和
 
# 训练部分
for epoch in range(epoch):  #数据集级别的循环，每个epoch循环一次数据集
    for step, (x_train, y_train) in enumerate(train_db):  #batch级别的循环 ，每个step循环一个batch
        with tf.GradientTape() as tape:  # with结构记录梯度信息
            y = tf.matmul(x_train, w1) + b1  # 神经网络乘加运算
            y = tf.nn.softmax(y)  # 使输出y符合概率分布（此操作后与独热码同量级，可相减求loss）
            y_ = tf.one_hot(y_train, depth=3)  # 将标签值转换为独热码格式，方便计算loss和accuracy
            loss = tf.reduce_mean(tf.square(y_ - y))  # 采用均方误差损失函数mse = mean(sum(y-out)^2)
            loss_all += loss.numpy()  # 将每个step计算出的loss累加，为后续求loss平均值提供数据，这样计算的loss更准确
        # 计算loss对各个参数的梯度
        grads = tape.gradient(loss, [w1, b1])
 
        # 实现梯度更新 w1 = w1 - lr * w1_grad    b = b - lr * b_grad
        w1.assign_sub(lr * grads[0])  # 参数w1自更新
        b1.assign_sub(lr * grads[1])  # 参数b自更新
 
    # 每个epoch，打印loss信息
    print("Epoch {}, loss: {}".format(epoch, loss_all/4))
    train_loss_results.append(loss_all / 4)  # 将4个step的loss求平均记录在此变量中
    loss_all = 0  # loss_all归零，为记录下一个epoch的loss做准备
 
    # 测试部分
    # total_correct为预测对的样本个数, total_number为测试的总样本数，将这两个变量都初始化为0
    total_correct, total_number = 0, 0
    for x_test, y_test in test_db:
        # 使用更新后的参数进行预测
        y = tf.matmul(x_test, w1) + b1
        y = tf.nn.softmax(y)
        pred = tf.argmax(y, axis=1)  # 返回y中最大值的索引，即预测的分类
        # 将pred转换为y_test的数据类型
        pred = tf.cast(pred, dtype=y_test.dtype)
        # 若分类正确，则correct=1，否则为0，将bool型的结果转换为int型
        correct = tf.cast(tf.equal(pred, y_test), dtype=tf.int32)
        # 将每个batch的correct数加起来
        correct = tf.reduce_sum(correct)
        # 将所有batch中的correct数加起来
        total_correct += int(correct)
        # total_number为测试的总样本数，也就是x_test的行数，shape[0]返回变量的行数
        total_number += x_test.shape[0]
    # 总的准确率等于total_correct/total_number
    acc = total_correct / total_number
    test_acc.append(acc)
    print("Test_acc:", acc)
    print("--------------------------")
 
# 绘制 loss 曲线
plt.title('Loss Function Curve')  # 图片标题
plt.xlabel('Epoch')  # x轴变量名称
plt.ylabel('Loss')  # y轴变量名称
plt.plot(train_loss_results, label="$Loss$")  # 逐点画出trian_loss_results值并连线，连线图标是Loss
plt.legend()  # 画出曲线图标
plt.show()  # 画出图像
 
# 绘制 Accuracy 曲线
plt.title('Acc Curve')  # 图片标题
plt.xlabel('Epoch')  # x轴变量名称
plt.ylabel('Acc')  # y轴变量名称
plt.plot(test_acc, label="$Accuracy$")  # 逐点画出test_acc值并连线，连线图标是Accuracy
plt.legend()
plt.show()
```



视觉方面
  卷积
  感受野
  池化
  全连接

智能车：
```python
import tensorflow as tf 
import numpy as np
import PIL
import re
root = 'F:/机器学习/智能车/hsv_img/'
im = PIL.Image.open(root+'0.jpg')
train_img = np.empty([538,720,1280])
train_label = np.zeros([538],dtype=np.int)
#读入图片数据

for i in range(537):
    im = PIL.Image.open(root+str(i)+'.jpg')
    im_array = np.array(im)
    train_img[i] = im_array
    
def readLabel():
    with open('F:/机器学习/智能车/train.list','r') as f:
        # label_raw = f.readline()
        # label_raw = label_raw[:-1]
        patt = re.compile(r'\d{1,4}')
        # findres = patt.findall(label_raw)
        # train_label[int(findres[0])] = int(findres[1])
        for i in range(537):
            label_raw = f.readline()
            label_raw = label_raw[:-1]
            findres = patt.findall(label_raw)
            train_label[int(findres[0])] = int(findres[1])         
readLabel()

#tf.transpose(train_label)
print(train_label.shape)
train_img = tf.reshape(train_img,[538,720,1280,1])
model = tf.keras.Sequential()
#model.add(tf.keras.layers.ZeroPadding2D((1,1),input_shape=(720,1280))) #定义输入层形状
model.add(tf.keras.layers.Conv2D(filters=24,kernel_size=(5,5),strides=2,input_shape=(720,1280,1),activation='relu'))
#model.add(tf.keras.layers.MaxPooling2D((10,10),strides=(2,2)))
model.add(tf.keras.layers.Conv2D(filters=32,kernel_size=(5,5),strides=2,activation='relu'))
model.add(tf.keras.layers.Conv2D(filters=64,kernel_size=(5,5),strides=2,activation='relu'))
model.add(tf.keras.layers.Conv2D(filters=64,kernel_size=(3,3),strides=2,activation='relu'))
model.add(tf.keras.layers.Conv2D(filters=64,kernel_size=(3,3),strides=1,activation='relu'))
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(100))
model.add(tf.keras.layers.Dropout(0.1))
model.add(tf.keras.layers.Dense(50))
model.add(tf.keras.layers.Dropout(0.3))
model.add(tf.keras.layers.Dense(1))
model.summary()
model.compile(optimizer='adam',
            loss = 'mse',
            metrics=['acc']
)
model.fit(train_img,train_label,epochs=10)
```

上采样：插值
下采样：卷积，池化

其它概念：

缓解过拟合：
降低模型复杂度
增加数据
数据增强
正则化
dropout
提前停止训练

优化器
学习率（参数调整粒度）




chatGPT

参考：
https://baijiahao.baidu.com/s?id=1648513303243551939&wfr=spider&for=pc
https://zhuanlan.zhihu.com/p/492763771
北京大学：tensorflow教程-曹健
